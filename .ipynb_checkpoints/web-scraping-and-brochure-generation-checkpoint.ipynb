{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cacb09db-8666-4864-80e0-eb344d27b020",
   "metadata": {},
   "source": [
    "# Web Scraping and Brochure Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa23574-c9e1-4cad-91ef-437c2bafbd9e",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This Jupyter notebook demonstrates an automated process for generating company brochures using web scraping and AI-powered content generation. The script leverages several key technologies and libraries to:\n",
    "\n",
    "1. Web Scraping: Retrieve and parse website content using requests and BeautifulSoup\n",
    "2. Link Extraction: Automatically identify and filter relevant website links\n",
    "3. AI-Powered Content Generation: Use OpenAI's GPT models to create engaging, professional brochures\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- Scrape website content dynamically\n",
    "- Extract and filter website links\n",
    "- Generate markdown-formatted brochures\n",
    "- Stream brochure content in real-time\n",
    "- Customize brochure generation with system prompts\n",
    "\n",
    "## Technical Components\n",
    "\n",
    "### Libraries:\n",
    "\n",
    "- Web Scraping: requests, BeautifulSoup\n",
    "- Environment Management: python-dotenv\n",
    "- AI Interaction: openai\n",
    "- AI Model: GPT-4o-mini\n",
    "- Output Format: Markdown\n",
    "\n",
    "## Usage\n",
    "To generate a brochure for a company:\n",
    "\n",
    "- Provide the company's website URL\n",
    "- Run the stream_brochure() function\n",
    "- Watch as the AI generates a dynamic, engaging brochure\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Activated Python environment\n",
    "- OpenAI API key\n",
    "- Required Python libraries installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b15308ff-920c-4178-affc-4da798aefdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import anthropic\n",
    "import google.generativeai\n",
    "import gradio as gr\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "10570e03-f285-4228-9ff7-a29997c70169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AIzaSyA_\n",
      "DeepSeek API Key exists and begins sk-b3\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GEMINI_API_KEY')\n",
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:5]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "5a69608f-9ace-4adf-ab15-6f946b955227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI, Anthropic, DeepSeek, or Google\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "claude = anthropic.Anthropic()\n",
    "\n",
    "google.generativeai.configure()\n",
    "\n",
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f28c946b-8905-4221-bf9c-5c00663a986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with links\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "38ca83cc-136f-417d-9cba-98b1f9525f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a system prompt for link relevance selection\n",
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You can decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, a Company page, or Careers/Jobs pages.\\n\"\n",
    "link_system_prompt += \"You should respond in JSON as in those examples:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"contact page\", \"url\": \"https://full.url/goes/here/contact\"},\n",
    "        {\"type\": \"social links page\": \"url\": \"https://another.full.url/social\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "95f0b1af-1978-455c-af08-20d1339ccb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a user prompt with website links for AI processing\n",
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d63d2-d95d-4716-8d7e-e5ed69fc06fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and filter relevant links from a website using OpenAI\n",
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "      ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8480d4-852d-4a5b-be22-e2f5e9381f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface = Website(\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f2b5d7-46c1-441f-aaf6-c40a42846b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_links(\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b978fc11-29ba-4160-94aa-988d30686691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect comprehensive details from a website's landing page and relevant links\n",
    "def get_all_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    links = get_links(url)\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += Website(link[\"url\"]).get_contents()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69959c7d-5991-432d-8443-4930ac1f2b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can personalize the tone, design, and sections... of your brochure\n",
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short humorous, entertaining, jokey, and professional brochure about the company for prospective customers, investors, and recruits. Respond in markdown.\\\n",
    "Include details of company culture, customers, and careers/jobs if you have the information. Include at the end of the brochure all the relevant links with their correct path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55799dd2-4411-4edb-8471-97bad12370c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a user prompt with company website details for brochure generation\n",
    "def get_brochure_user_prompt(url):\n",
    "    user_prompt = f\"You are looking at a company hosted there: {url}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fba359d-f8d3-4747-b604-c107e64c930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the stream parameter, the results stream back from OpenAI\n",
    "def stream_brochure_gpt(url):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(url)}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de11dc-8e1f-4a62-b3c9-0d3980c912f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure_claude(url): \n",
    "    result = claude.messages.stream(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0.7,\n",
    "        system=system_message,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(url)},\n",
    "        ],\n",
    "    )\n",
    "    response = \"\"\n",
    "    with result as stream:\n",
    "        for text in stream.text_stream:\n",
    "            response += text or \"\"\n",
    "            yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab19aa4-bdff-4665-8ad0-2bb75b6b8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure_gemini(url):\n",
    "    gemini = google.generativeai.GenerativeModel(\n",
    "    model_name='gemini-1.5-flash',\n",
    "    system_instruction=system_message)\n",
    "    text_response = \"\"\n",
    "    response = gemini.generate_content(get_brochure_user_prompt(url), stream=True)\n",
    "    for chunk in response:\n",
    "     text_response += chunk.text\n",
    "    yield text_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bbf9bb-5aa9-49ee-a55a-d3d4b3784d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure_deepseek(url):\n",
    "    response = deepseek.chat.completions.create(\n",
    "        model=\"deepseek-chat\", # deepseek-chat or deepseek-reasoner \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(url)},\n",
    "        ],\n",
    "        temperature=1.5,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in response:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f56f956-1ba5-42e5-952c-c68982ddb0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_brochure(url, model):\n",
    "    prompt = f\"Please generate a company brochure for the website, at this {url} Here is their landing page:\\n\"\n",
    "    if model==\"GPT\":\n",
    "        result = stream_brochure_gpt(url)\n",
    "    elif model==\"Claude\":\n",
    "        result = stream_brochure_claude(url)\n",
    "    elif model==\"DeepSeek\":\n",
    "        result = stream_brochure_deepseek(curl)\n",
    "    elif model==\"Gemini\":\n",
    "        result = stream_brochure_gemini(curl)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    yield from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3789a3c4-664b-4003-9553-ba2a25cd8ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define this variable and then pass js=force_dark_mode when creating the Interface to force dark mode\n",
    "force_dark_mode = \"\"\"\n",
    "function refresh() {\n",
    "    const url = new URL(window.location);\n",
    "    if (url.searchParams.get('__theme') !== 'dark') {\n",
    "        url.searchParams.set('__theme', 'dark');\n",
    "        window.location.href = url.href;\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bc57ac-d19b-4223-a9b8-f0d2e78be508",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.Interface(\n",
    "    fn=generate_brochure, \n",
    "    inputs=[gr.Textbox(label=\"Link\", placeholder=\"https://github.com/antomarchim\"), gr.Dropdown([\"GPT\", \"Claude\", \"Gemini\", \"DeepSeek\"])],\n",
    "    outputs=[gr.Markdown(label=\"Brochure\")], \n",
    "    flagging_mode=\"never\", \n",
    "    js=force_dark_mode\n",
    ").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06dec40-f4d2-4bed-8879-ab64f1e8279b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f831333-015a-4f7e-bdb9-0f65e4aa52d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
