{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Speech and Image Creation\n",
    "\n",
    "This Jupyter notebook implements a multimodal AI assistant that combines chat, image generation, and text-to-speech capabilities using OpenAI's APIs. The application provides an interactive interface built with Gradio that allows users to:\n",
    "\n",
    "- Engage in text-based conversations with an AI assistant\n",
    "- Generate images based on text prompts using DALL-E 3\n",
    "- Convert text responses to speech using OpenAI's text-to-speech API\n",
    "\n",
    "## Key Components\n",
    "### API Integration for\n",
    "\n",
    "- Chat completions (GPT-4 Mini model)\n",
    "- Image generation (DALL-E 3)\n",
    "- Text-to-speech synthesis (TTS-1 model with Alloy voice)\n",
    "\n",
    "### User Interface\n",
    "\n",
    "- Built using Gradio blocks\n",
    "- Features a split-screen layout \n",
    "\n",
    "### Core Functionality\n",
    "\n",
    "- Real-time chat capabilities with message history\n",
    "- Automatic image generation based on conversation context\n",
    "- Text-to-speech conversion of AI responses\n",
    "\n",
    "### Technical Requirements\n",
    "\n",
    "- Python libraries: openai, gradio, PIL, pydub, dotenv\n",
    "- OpenAI API key (loaded from environment variables)\n",
    "- Audio playback capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import gradio as gr \n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc7eb7-405c-4b86-b888-f197c9045ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "MODEL_IMAGES = \"dall-e-3\"\n",
    "MODEL_CHAT = \"gpt-4o-mini\"\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5612161b-0785-4762-96f2-cd1a8612e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are just receiving prompts and reply and reply exactly the sentence I have just said\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d11233-12b3-4cd5-bb36-e0d6978cce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=MODEL_CHAT, messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddaf292-8501-4a15-850f-0562cde7803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generation(image):\n",
    "    image_response = openai.images.generate(\n",
    "        model=MODEL_IMAGES,\n",
    "        prompt=f\"You will create an {image}\",\n",
    "        size=\"1024x1024\",\n",
    "        n=1, \n",
    "        response_format=\"b64_json\"\n",
    "    )\n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return Image.open(BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fb54e2-5f8b-427e-b85a-20896172d03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "    image = arguments.get('image')\n",
    "    result = image_generation(image)\n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps({\"image\": image, \"result\": result}),\n",
    "        \"tool_call_id\": tool_call.id\n",
    "    }\n",
    "    return response, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be426bdd-deb3-4cb3-bde9-814a92da36bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\"type\": \"function\", \"function\": image_function}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0dffff-68cd-443b-8719-dc73ce85b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "      model=\"tts-1\",\n",
    "      voice=\"alloy\",    \n",
    "      input=message\n",
    "    )\n",
    "    \n",
    "    audio_stream = BytesIO(response.content)\n",
    "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
    "    play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161023cc-9cce-4309-8b79-9897f0c91cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "talker(\"Bonjour, comment Ã§a va aujourd'hui\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ca7a9b-3410-47f7-9a58-4fb3d11e2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "    response = openai.chat.completions.create(model=MODEL_CHAT, messages=messages)\n",
    "    image = image_generation(response)\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "    talker(reply)\n",
    "    \n",
    "    return history, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336526f6-e77c-4204-b7a9-f103094fa33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing in inbrowser=True in the last line will cause a Gradio window to pop up immediately.\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "        image_output = gr.Image(height=500)\n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def do_entry(message, history):\n",
    "        history += [{\"role\":\"user\", \"content\":message}]\n",
    "        return \"\", history\n",
    "\n",
    "    entry.submit(do_entry, inputs=[entry, chatbot], outputs=[entry, chatbot]).then(\n",
    "        chat, inputs=chatbot, outputs=[chatbot, image_output]\n",
    "    )\n",
    "    clear.click(lambda: None, inputs=None, outputs=chatbot, queue=False)\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311ff259-3724-48ba-a653-776e740bdc3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
