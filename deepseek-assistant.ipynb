{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6bbcb5c-e34a-4783-99f7-5f88ed79c4d0",
   "metadata": {},
   "source": [
    "# DeepSeek Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b1c4f7-97d8-4d65-b039-afbc712043a0",
   "metadata": {},
   "source": [
    "DeepSeek is a cutting-edge, open-source large language model (LLM) designed to deliver high-performance AI capabilities at an exceptionally low cost. Built with accessibility and affordability in mind, DeepSeek empowers developers, researchers, and businesses to leverage advanced natural language processing without the hefty price tag often associated with proprietary models.\n",
    "\n",
    "What sets DeepSeek apart is its competitive edge—it rivals the performance of leading LLMs while remaining open-source, enabling customization and transparency. Whether you're building intelligent applications, conducting research, or exploring AI-driven solutions, DeepSeek offers a cost-effective, scalable, and community-driven alternative to expensive, closed-source models.\n",
    "\n",
    "With DeepSeek, you get the best of both worlds: cutting-edge AI technology and the freedom to innovate without breaking the bank. Dive into the future of open-source AI with DeepSeek—where affordability meets excellence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85882b7c-0feb-443e-8bd4-3d1aba5854cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661a878-1f2d-4cc6-a43d-97202ab2dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can obtain an api key directly on https://platform.deepseek.com. \n",
    "# Save your api key as DEEPSEEK_API_KEY in a .env file in your root folder and NEVER SHARE IT\n",
    "load_dotenv()\n",
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "client = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54972521-3d6c-4e59-9739-8da03d793b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful assistant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4585dba1-70a0-45b0-8b21-29e180cc1132",
   "metadata": {},
   "source": [
    "## Temperature on DeepSeek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d511cc8e-ca3d-4215-96d0-d394b556b3f5",
   "metadata": {},
   "source": [
    "The default value of temperature is 1.0.\n",
    "\n",
    "- The team at DeepSeek recommends users to set the temperature according to their use case listed in below.\n",
    "\n",
    "| USE CASE | TEMPERATURE |\n",
    "|:--------|:--------:|\n",
    "|  Coding / Math   |  0.0   |  \n",
    "|  Data CLeaning / Data Analysis   |  1.0   | \n",
    "|  General Conversation   |  1.3   |\n",
    "|  Translation   |  1.3   |\n",
    "| Creative Writing / Poetry   |  1.5   | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091bb598-440b-4372-a3f3-d1ea0453dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello_deepseek(user_prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\", # deepseek-chat or deepseek-reasoner \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in response:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5677a4b3-87dc-4955-b483-35fa6698d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include it in your Gradio Interface Configuration to force dark mode\n",
    "force_dark_mode = \"\"\"\n",
    "function refresh() {\n",
    "    const url = new URL(window.location);\n",
    "    if (url.searchParams.get('__theme') !== 'dark') {\n",
    "        url.searchParams.set('__theme', 'dark');\n",
    "        window.location.href = url.href;\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4763e18-3e13-4d49-a53e-2b2c22e6f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.Interface(\n",
    "    fn=hello_deepseek,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\", lines=6)],\n",
    "    outputs=[gr.Markdown(label=\"Deepseek:\")],\n",
    "    flagging_mode=\"never\",\n",
    "    # js=force_dark_mode\n",
    ").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448a1744-eb43-43be-92ed-e265a8d9ab3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
